# Dockerハンドブック
参考リンク: https://shimo5.me/post/2020-09-07/

### コンテナ化とDockerの概要
コンテナ化とは、コードと依存関係をパッケージ内にカプセル化する技術
環境依存をなくすことができるもの
コンテナと呼ばれる隔離された環境でアプリケーションを実行することができる
コンテナは、ハイパーバイザーを必要とせずにホストOSのカーネルで直接実行することができる。
ハイパーバイザとは、空っぽのHDDの中に仮想マシンを作ること
ホストOSとは、仮想マシン自体を動かしているPC本体のOSのこと
カーネルとは、アプリケーションとハードウェアの中間のようなもの
コンテナは以上の理由から、複数のコンテナを同時に実行することができる

各コンテナは、アプリケーションと依存関係の全てが含まれていて他の依存関係から分離されている。これらのコンテナをレジストリを通じてイメージとして交換することができ、サーバに直接デプロイすることもできる。

### 仮想マシンとコンテナ
仮想マシンは仮想CPU、メモリ、ストレージ、OSを備えた物理コンピュータシステムと同じようにエミュレータされたもの
ハイパーバイザーは、CPU、メモリ、ストレージのようなリソースをゲスト仮想マシン間で再割り当てすることができる
ハイパーバイザーには次の2タイプがある。
- Type1 (ネイティブまたはベアメタル)
- Type2 (ホストハイパーバイザ)

コンテナは、コードと依存かんけを一緒にパッケージ化することができるアプリケーション層の抽象概念。物理マシン全体を仮想化する代わりに、コンテナはホストOSだけを仮想化する

コンテナは、物理マシンとOS上に配置される。各コンテナは、ホストOSのカーネルと共有する

### Dokcerのインストール
https://www.docker.com/products/docker-desktop

### DockerでのHelloWorld
ステータスはEXITED(0)でコンテナが実行され、正常に終了した
Dockerのアーキテクチャとイメージとコンテナ、レジストリについて理解する必要がある
### Dockerアーキテクチャ
Dockerはクライアントサーバアーキテクチャを使用する。エンジンは、3つの主要コンポーネントで構成されている
クライアントサーバアーキテクチャとは、中央に能力の高いコンピュータを配置し、直接中央のコンピュータと端末を接続して利用する形態

1. **Dokcerデーモン**: デーモンは、裏側で実行されているアプリケーション。イメージ、コンテナ、ネットワークなどのDockerオブジェクトを管理している
2. **Dockerクライアント**: クライアントは、docker run させると、デーモンにタスクを実行させるようにする
3. **RESTAPI**: デーモンクライアント間のやり取りはRESTで行われる。

### イメージとコンテナ
イメージは、コンテナを作成するための自己完結ファイル。DokcerHub等のレジストリを介して、イメージの交換ができる。他の人が作成したイメージに、内容を追加して使うこともできる

scratchからもイメージの作成ができる。DockerFileを編集して再構築すると、変更部分が最上位レイヤーに再構築される。

コンテナは、イメージの実行可能なインスタンス。イメージをpullして実行すると、隔離された環境が作成される。

### レジストリ
レジストリは、Dockerイメージのストレージ(DockerHub)
ユーザなら誰でも、DokcerHubからイメージをpushしたり、pullしたりすることができる

### 全体像
`docker run hello-world`をした時に発生すること
1. `docker run hello-world`を実行する
2. Dockerクライアントは、Dockerデーモンにhello-worldイメージを使ってコンテナを実行することを通知する
3. Dockerデーモンは、DockerHubから最新のhello-worldイメージをpullしてくる
4. pullしてきた、最新イメージからコンテナを作成する
5. 作成したコンテナを実行する

ローカルに存在しない、imageがpullされると、ローカルキャッシュに残る
しかし、Ver.UPされると、imageを再度fetchしてくる（:latest)

### コンテナの操作
Dockerデーモンには、CUIを使用してコマンドを渡す。
Dockerのより高度なコンテナ操作について学習する

### コンテナを実行する
コンテナの作成及び実行
`docker run <image名>`
実は、`docker run`の裏側では2つのコマンドが走っている
1. `docker create <image名>`: 指定されたイメージからコンテナを作成し、コンテナIDを返す。
2. `docker start <コンテナID>`: 既に作成されたコンテナの指定されたIDからコンテナを起動する。

hello-worldコンテナの作成には以下のコマンド
`docker create hello-world`
CUIはコンテナIDの出力に長い文字列を出力するが、実際は最初の12文字で十分
`docker start abcdefghijkl`

以上を実行すると、何も起こらなかったように見えるが、出力ストリームに接続しなかったから。通常の実行時には、`STDIN`と`STDOUT`、`STDERR`が開かれる。
コンテナの出力イメージに接続するには、-aオプションを使用する必要がある。
`docker start -a ab59dbf58b70`
全てが正常に実行されると、その旨出力される
`start`コマンドを使用して、まだ実行されていないコンテナを実行できる。
`run`コマンドを使用すると、`create`と`start`が同時に走るため、毎回新しいコンテナが作成される。

コンテナの確認をする時は、dashboardからするか、`docker ps -a`をする

### コンテナの再起動
`docker restart`でコンテナの再起動をすることもできる

### コンテナの削除
`docker rm `でコンテナを削除することもできる

### インタラクティブモードでのコンテナ実行
これまでは、hello.cプログラムから構成されるhello-worldイメージのみを実行していた。
しかし、全てのイメージは、それほど単純ではない。
イメージは、OS自体をカプセルかできる。
Ubuntu、Febra、DebialなどのLinuxは、全てのDockerHubで利用可能
公式のubuntuイメージを使用して、コンテナ内でubuntuを実行しよう
-itオプションをつけないと、何も起こらない
`docker run -it ubuntu`
-itオプションが必要な理由は、Ubuntuイメージが起動時にbashを開始するように構成されているから。
つまり、何のコマンドも入力しなければ、bashは何もしない
コンテナないのプログラムとやり取りをするには、インタラクティブセッションが必要であることをコンテナに明示的に知らせる必要がある。

インタラクティブモードでコンテナを実行するときは、-itオプションを使用する必要がある。`docker run -it node`または`docker run -it python`を実行すると、nodeまたはpythonとインタラクティブにやり取りをすることができる

### 実行可能イメージを使用してコンテナを作成する
Dockerイメージの中には、エントリポイントで構成されているものがある。
エントリポイントを使用すると、実行可能ファイルとして実行されるコンテナを構成できる。
エントリポイントを使用すると、実行可能ファイルとして実行されるコンテナを構成できる
`docker run ubuntu ls`
-itオプションを使用していないことに注意、bashとやり取りをしようとするのではなく、出力が必要なだけだから。

### デタッチモードでコンテナを実行する
PCでRedisサーバを実行する。Redisは非常に高速なインメモリデータベース(HDD等ではなく、メモリ上で保存する感じ)
キャッシュとして利用されることが多い
`docker run redis`

### 実行中のコンテナ内でshellを起動する
`docker exec -it 2115dd959ba6 sh`
ここで有効なshellコマンドを実行できる

### 実行中のコンテナからログにアクセスする
logsコマンドを使用して、実行中のコンテナからログを取得することもできる
`docker logs <コンテナID>`

### 実行中のコンテナを停止または強制停止する
`docker stop <コンテナID>`正常停止
`docker kill <コンテナID>`強制停止

### ポートマッピング
`docker run nginx`
Nginxは実行し続けることを意図しているため、-dオプションを使うこともできる
`docker run nginx`をしても、コンテナ内のポート80で実行されているため、ホストOSではコンテナ内で何が行われているかはわからないため、
`docker run -p <ホストポート:コンテナポート nginx>`
`docker run -p 80:80 nginx`
以上を実行すれば、ホストOSとコンテナのポート80が対応づけされる

### コンテナ分離のデモ
コンテナはホストOSだけではなく、コンテナ同士からも分離されている
`docker run -it ubuntu`
コンテナを分離させているので、他のコンテナに影響を与えない

### カステムイメージの作成
Dockerクライアントを使用して、コンテナを操作する多くの方法を理解したら、カスタムイメージの作成方法を学習する
イメージの構築、コンテナの作成、他のユーザとの共有に関する多くの重要な概念を学ぶ

### イメージ作成の基本
Dockerfileはテキストドキュメントであり、Dockerデーモンがイメージを作成して、ビルドするための一連の指示が含まれている
イメージ作成の基本を理解するために、シンプルなカスタムNodeイメージを作成する。公式nodeイメージがどのように機能するか
`dokcer run -it node`
上記コマンドだと、インタラクションモードで起動するが、
ここでjsコードを実行できるので、カスタムnodeイメージを作成する。
Dockerfileの各行は命令であり、各命令は新しいレイヤを作成する。

全ての有効なDockerfileは、FROM命令で始める必要がある。
この命令は、新しいビルドステージを開始し、ベースイメージを設定する。
ubuntuをベースイメージとして設定することにより、Ubuntuイメージの全ての機能をイメージ内で使用できるようになる。
Ubuntu機能を使用できるようになったので、apt-getを使用してnodeをインストールできる。
`RUN apt-get update`
`RUN apt-get install nodejs -y`
RUN命令は、現在のイメージ上の新しいレイヤでコマンドを実行し、結果を保持する。なので上記手順を経ると以下コマンドでNodeを参照できるようになる。
`CMD ["node"]`
CMD命令の目的は、実行中のコンテナにデフォルトを提供すること。これらのデフォルトには、実行可能ファイルを含めることも省略することもできる。その場合は、ENTRYPOINT命令を指定する必要がある。Dockerfileに含めることができるCMD命令は一つだけ。シングルクォートは無効。

このDockerfileからイメージをビルドするために、buildコマンドを使用する。
`docker build <ビルドコンテキスト>`
buildコマンドには、Dockerfileとビルドコンテキストが必要。コンテキストは、指定された場所にあるファイルとディレクトリのセット。Dockerはコンテキスト内でDockerfileを探し、イメージを構築する。
`docker build .`
ここでは、公式Nodeイメージと同じように、jsコードを実行できる。

### 実行可能イメージを作成する
イメージは通常の実行可能ファイルと同じように追加の引数をとることができる。
カスタムbashイメージを作成し、前のサブセクションで行ったように引数を渡す。
`FROM alpine`
`RUN apk add --update bash`
`ENTORYPOINT ["bash"]`
alpineイメージをベースとして使用している。
alpineにはデフォルトでbashが付属していないため、apkを使用してbashをインストールする。
ENTORYPOINTを追加したことで、任意の引数を渡すことができる。全てのファイルとディレクトリのリストを表示するには、以下のコマンド
`docker run 2ddce8d49bb4 -c ls`
-cオプションは、Dockerクライアントとは関係なく、bashコマンドラインオプションであり、後続の文字列からコマンドを読み取る

### Expressアプリケーションのコンテナ化
これまでは追加のファイルを含まないイメージのみを作成していた。
このサブセクションでは、ソースファイルを含むコンテナ化について学習する。
プロジェクトコードリポジトリのクローンを作成した場合は、express-apiディレクトリ内に移動する。これは、port3000で実行され、単純なjsonペイロードを返すRESTAPIです。

1. npm installを実行して、必要な依存関係をインストールする
2. npm run startを実行して、アプリケーションを起動する。

上記をDockerでやる場合には、以下の手順を実行する必要がある。
1. Nodeアプリケーションを実行できるベースイメージの作成
2. package.jsonファイルをコピーして、`npm run start`を実行して、依存関係をインストール
3. 必要なプロジェクトファイルを全てコピー
4. `npm run start`でアプリケーションを起動する。

プロジェクトディレクトリ内に新しいDockerfileを作成して、ファイルの中に配置する。
以下のDockerfile書く
`FROM node`

`WORKDIR /usr/app`

`COPY ./package.json ./`
`RUN npm install`

`COPY . .`

`CMD [ "npm", "run", "start" ]`

ベースイメージとしてNodeを使用している。WORKDIRは、記述箇所以降の全ての命令の作業ディレクトリを設定するもの。ディレクトリにcdする感じ
COPYは、./package.jsonを作業ディレクトリにコピーする。WORKDIRで作業ディレクトリを設定したため、`.`は/usr/appを参照する。package.jsonがコピーされたら、RUNで依存関係をインストールする。
CMDでは、npmを実行可能ファイルとして設定し、runとstartを引数として渡す。つまりコンテナ内で`npm run start`として解釈される。

### ボリュームの操作
このサブセクションでは、Reactを使ってモダンフロントエンドで作業していると想定する。
プロジェクトコードリポジトリをクローンしたら、vite-counterディレクトリに移動する。
このアプリケーションを開発モードで実行するには、
1. `npm install`を実行して、依存関係をインストールする
2. `npm run dev`を実行して、開発モードで起動する。
Dockerfile.devを作成し、内容を記述する
コマンドを実行して、イメージをビルドする。
`docker build -f Dockerfile.dev .`
Dockerは、ビルドのコンテキスト内でDockerfileを探すようにプログラムされている。しかし、ファイルにDockerfile.devという名前を付けたため、-fオプションを使用して、Dockerにファイル名を知らせてあげる必要がある。
アクセスすると、vueアプリケーションを見ることができる
フロントエンドフレームワークには、ホットリロード機能が付属されている。普通は、コードの変更を行うとホットリロード機能が働くが、ホストシステムのコードが変更されるだけで、コンテナ内のコードを変更するわけではないので効かない。
この問題の解決策が、コンテナにソースコードのコピーをさせる代わりに、コンテナにホストから直接ファイルアクセスをさせる方法。
runコマンド用の-vオプションがある。-vオプションの構文は以下の通り
`docker run -v <ホストディレクトリへの絶対パス>:<コンテナの作業ディレクトリへの絶対パス> <イメージID>`
上記実行すると、失敗する。
node_modulesを実行すると成功する？？

Dockerfile.devの4行目を見ると、`RUN npm install`が明確に記述されているのに、なぜエラーを吐くか

ボリュームを使用する場合、コンテナはホストシステムから直接ソースコードにアクセスする。しかし、ホストシステムには依存関係をインストールしていない。
依存関係をインストールすると問題を解決できるが、理想的ではない。
一部の依存関係は、インストールするたびにソースからコンパイルされるから。
また、OSとしてWindowsまたはMacを使用している場合、OS用にビルドされたバイナリは、Linuxを実行しているコンテナ内では機能しない。
この問題を解決するには、Dockerの2種類のボリュームについて知っておく必要がある。

- 名前付きボリューム: これらのボリュームには、コンテナ外部からの特定のソースがある。例えば、-v ($PWD):/usr/appです。
- 匿名ボリューム: これらのボリュームには特定のソースがない。-v/usr/app/node_modules。コンテナが削除されると、匿名ボリュームは手動でクリーンアップするまで残る。

node_modulesディレクトリが上書きされないようにするためには、匿名ボリューム内に配置する必要がある。
`docker run -p 3000:3000 -v /usr/app/node_modules -v /Users/p10119/src/docker-test/vue-test:/usr/app <imageID>`

ここでは、新しい匿名ボリュームの追加を行った。

このコマンドは繰り返し実行するには長すぎるので、絶対パスの代わりにシェルコマンドで代用する。
`docker run -p 3000:3000 -v /usr/app/node_modules -v $(pwd):/usr/app d4fc36e848e9`

### マルチステージビルド
ここでは、Dockerv17.05で導入されたマルチステージビルドを取り扱う
前のサブセクションでは、Dockerfile.devファイルを作成した。
Vueまたは、Reactアプリケーションのプロダクションビルドを作成することは、多段階ビルドプロセスの完璧な例。

ビルドプロセスには2つのステップがある。
`npm run build`を実行すると、アプリケーションが一括りのjs, css, index.htmlにコンパイルされる。プロダクションビルドは、プロジェクトルートの/distディレクトリ内で利用できる。ただし、開発バージョンとは異なり、プロダクションビルドには手の込んだサーバが付属されていない。
プロダクションファイルでサーバを立ち上げるには、Nginxを使用する必要がある。ステージ1でビルドされたファイルをNginxのドキュメントルートにコピーして、利用可能にする。
前の2つのプロジェクトで行ったような手順を確認したい場合には、次のようになる。
1. Nodeアプリケーションを実行できるベースイメージ(node)を使用する。
2. package.jsonファイルをコピして、npm run installを実行して、依存関係をインストールする。
3. 必要なプロジェクトファイルを全てコピーする。
4. npm run buildを実行時てプロダクションビルドを作成する。
5. 本番ファイルの実行を可能にする別のベースイメージ(nginx)を使用する。
6. 本番ファイルを/distディレクトリからデフォルトのドキュメントルートにコピーする

`FROM node as builder`

`WORKDIR /usr/app`

`COPY ./package.json ./`
`RUN npm install`

`COPY . .`

`RUN npm run build`

`FROM nginx`

`COPY --from=builder /usr/app/dist /usr/share/nginx/html`

複数のFROMが記述されている。マルチステージビルドプロセスでは、複数のFROMを使用することができる。最初のFROMは、nodeをベースイメージとして設定し、依存関係をインストールし、全てのプロジェクトファイルをコピーして、`npm run build`を実行する。最初のステージをbuilderと命名。
2段階目では、ベースイメージとしてnginxを使用している。第1ステージで構築された/usr/app/distディレクトリから第2ステージのusr/share/nginx/htmlディレクトリに全てのファイルをコピーする。COPYの--fromオプションを使用すると、ステージ間でファイルのコピーができる。

このマルチステージビルドプロセスからの出力イメージは、ビルドされたファイルのみを含むため、追加のデータを含まないNginxベースのイメージ。その結果、サイズが最適化され、軽量になっている。

### ビルドされたイメージをDocker Hubにアップロードする

ここでは、DockerHubへのpush方法について学ぶ。
Dockerimageをアップロードするためには、タグをつける必要がある。
buildコマンドで、-tオプションを使用して、タグをつけることができる。
`docker build -t <タグ> <コンテキスト>`
タグの一般的な規則は以下の通り
`<DockernのID>/<image名>:<imageのver>`
そして、imageをDockerHubへアップロードするには、pushコマンドを使用する。
`docker push <DockerId>/<imageタグとversion>`
このimageからコンテナを実行するための構文は以下の通り
`docker run <DockerID>/<imageタグとversion>`

### Docker Composeを使用したマルチコンテナアプリケーションの操作
これまでは、一つのコンテナのみで構成されるアプリケーションを扱ってきた。
次は、複数のコンテナを持つアプリケーションを想定する。DB, バックエンドAPI, フロントAppを一緒に使用する必要があるアプリケーションが想定される。
Docker-composeを使用する。
Dockerのドキュメントによると、下記のように記述されている。
Composeは、マルチコンテナのDockerアプリを定義して実行するツール。
Composeでは、YAMLファイルを使用してアプリケーションを設定する。
Composeはすべての環境で機能するが、開発とテストに重点を置いているため、本番環境でComposeを使用することはおすすめしない。

### Docker Composeの基本
note-apiディレクトリで作業を行う。
これは、ノートの作成、読み取り、更新、削除を行うCRUDAPIです。
`FROM node:lts`

`WORKDIR /usr/app`

`COPY ./package.json .`
`RUN npm install`

`COPY . .`

`CMD [ "npm", "run", "dev" ]`

package.jsonファイルをコピーして、依存関係をインストールし、プロジェクトファイルをコピーして、npm run devでサーバを起動する。

Composeの使用は、基本的に3つのステップ

1. Dockerfileを使用し、アプリを定義するのでどこでも再現可能
2. アプリを構成するサービスをdocker-compose.ymlで定義して、隔離された環境で一緒に実行できるようになる。
3. docker-compose upを実行すると、Composeが起動し、アプリ全体が実行される。

サービスは基本的に、いくつかの追加要素を持つコンテナです。最初のymlファイルを書き始める前に必要なものをリストアップしてみよう

1. api プロジェクトルートのDockerfile.devを使用して実行されるExpressアプリケーションコンテナ
2. db 公式のpostgresイメージを使用して、実行されるPostgreSQLインスタンス

プロジェクトルートで新しいdocker-compose.ymlファイルを作成して、最初のサービスを定義してみよう。
```
version 3.8

services:
    db:
        image: postgres:12
        volumes:
            - ./docker-entrypoint-initdb.d:/docker-entorypoint-initdb.d
        environment:
            POSTGRES_PASSWORD: iasdjffasdfas
            POSTGRES_DB: notesdb
```
すべての有効なdocker-compose.ymlファイルは、ファイルバージョンを定義することから始まる。
YMLファイル内のブロックは、インデントによって定義される。
servicesブロックは、アプリケーション内の各サービスまたはコンテナの定義を保持する。dbはservicesブロック内のサービス
dbブロックはアプリケーションの新しいサービスを定義し、コンテナを開始するために必要な情報を保持する。
コンテナを実行するには、すべてのサービスに事前に構築されたイメージまたはDockerfileが必要。dbサービスには、公式のPostgreSQLイメージを使用している。
プロジェクトルートのdocker-entrypoint-initdb.dディレクトリには、データベースのテーブルをセットアップするためのSQLファイルが含まれている。
このディレクトリは、初期化スクリプトを保持するためのもの。
docker-compose.ymlファイル内のディレクトリをコピーする方法はないため
、ボリュームを使用する必要がある。

environmentブロックは環境変数を保持する。有効な環境変数リストは、DockerHubのimagepageに保存されている？？
POSTGRES_PASSWORD変数は、サーバのデフォルトパスワードの設定を行い、POSTGRES_DBは指定された名前でDBの作成を行う。

次に、apiサービスを追加する。インデントをdbサービスと一緒にする

```
インデント調整

    api:
        build:
            context .
            dockerfile: Dockerfile.dev
        volumes:
            - /usr/app/node_modules
            - ./:/usr/app
        ports:
            - 3000:3000
        environment:
            DB_CONNECTION: pg
            DB_HOST: db # データベースサービス名と同じ名前を使用
            DB_PORT: 5432
            DB_USER: postgres
            DB_DATABASE: notesdb
            DB_PASSWORD: iasdjffasdfas
```

apiサービス用のビルドイメージは存在しないが、Dockerfile.devがある。buildブロックは、ビルドのContextと使用するDockerfileのfilenameを定義する。ファイル名がDockerfileの場合、filenameは不要

ボリュームのマッピングは、前のセクションで見たものと同様。node_modulesディレクトリ用の匿名ボリュームとプロジェクトルート用の名前付きボリューム

ポートマッピングも前のセクションと同じように機能する。構文は<ホストシステムポート>:<コンテナポート>
environmentブロックでは、DB接続のセットアップに必要な情報を定義している。Knex.jsをORMとして使用して、DBに接続するための情報を定義している。DB_POSTとDB_USERに関しては、postgreSQLサーバのデフォルト。DB_DATABASEとDB_PASSWORDはdbサービスと一致する必要がある。DB_CONNECTION: pgはPostgreSQLを使用していることをORMに示す。
docker-compose.ymlファイルで定義されている全てのサービスは、サービス名を使用してホストとして使用できる。そのため、apiサービスは、127.0.0.1のようなアドレスではなくホストとして扱うことで、実際にdbサービスに接続できる。そのため、DB_HOSTの値はdbとしている。

docker-compose.ymmlが完成したので、アプリケーションを起動する